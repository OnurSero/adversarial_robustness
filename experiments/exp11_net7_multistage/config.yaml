script_path: train_finetune_adv_multistage.py
n_repeat : 1
adv_is_fast : True
data_unsupervised:
  path : data\mnist.py
  batch_size : 20
  loader_sizes : [1, 1]
data_supervised:
  path : data\mnist.py
  batch_size : 25
  loader_sizes : [45000, 5000]
model:
  path : experiments\exp11_net7_multistage\net7_multi.py
  module_name : TwoStageNet

trainer_sup:
  early_stopping : True
  enabled : True
  part_reconstruction_loss_multiplier : 0
  model_name : checkpoint
  loss_fn : nll
  n_epochs : 5
  train_part_i : 2
  checkpoint_path : experiments\exp11_net7_multistage
  log_interval : 400
  finetune_n_layers : all
  optimizer:
    name : Adam
    #momentum : 0.5
    lr : 0.003
  lr_scheduler:
    name : LinearLR
    start_factor : 1.0
    end_factor : 0.1
    total_iters : 50
