script_path: train_finetune_adv.py
n_repeat : 3
data_unsupervised:
  path : data\cifar10.py
  batch_size : 20
  loader_sizes : [1, 1]
data_supervised:
  path : data\cifar10.py
  batch_size : 25
  loader_sizes : [45000, 5000]
model:
  path : experiments\exp10_net7_large_double_quantize\net7.py
  module_name : Net

trainer_sup:
  early_stopping : True
  enabled : True
  part_reconstruction_loss_multiplier : 0
  model_name : checkpoint
  loss_fn : nll
  n_epochs : 5
  train_part_i : 2
  checkpoint_path : experiments\exp10_net7_large_double_quantize
  log_interval : 400
  finetune_n_layers : all
  optimizer:
    name : Adam
    #momentum : 0.5
    lr : 0.003
  lr_scheduler:
    name : LinearLR
    start_factor : 1.0
    end_factor : 0.1
    total_iters : 50
