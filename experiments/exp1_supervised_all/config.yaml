script_path: train_finetune.py
n_repeat : 1
data_unsupervised:
  path : data\cifar10.py
  batch_size : 20
  loader_sizes : [1, 1]
data_supervised:
  path : data\cifar10.py
  batch_size : 25
  loader_sizes : [45000, 5000]
model:
  path : model\net4.py
  module_name : Net

trainer_unsup:
  enabled : False
  early_stopping : True
  model_name : checkpoint
  loss_fn : rl
  n_epochs : 5
  train_n_layers : 2
  checkpoint_path : experiments\exp1_supervised_all
  log_interval : 400
  optimizer:
    name : SGD
    momentum : 0.5
    lr : 0.001
  lr_scheduler:
    name : LinearLR
    start_factor : 1.0
    end_factor : 0.3
    total_iters : 3

trainer_sup:
  early_stopping : True
  enabled : True
  model_name : checkpoint
  loss_fn : nll
  n_epochs : 150
  checkpoint_path : experiments\exp1_supervised_all
  log_interval : 400
  finetune_n_layers : all
  optimizer:
    name : Adam
    #momentum : 0.5
    lr : 0.003
  lr_scheduler:
    name : LinearLR
    start_factor : 1.0
    end_factor : 0.1
    total_iters : 50
