{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: data\\cifar10.py\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Created 14 parts.\n",
      "Enable all parts\n",
      "checkpoint to cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tsize mismatch for se1.fixed_weights: copying a param with shape torch.Size([25, 20, 28, 28]) from checkpoint, the shape in current model is torch.Size([1, 20, 28, 28]).\n\tsize mismatch for se2.fixed_weights: copying a param with shape torch.Size([25, 40, 12, 12]) from checkpoint, the shape in current model is torch.Size([1, 40, 12, 12]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20120/4154482379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mi_part\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mtrn_trained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer_sup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpart_manager_trained\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mmodel_trained\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"experiments\\exp9_net6\\checkpoint.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mmodel_trained\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1484\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Net:\n\tsize mismatch for se1.fixed_weights: copying a param with shape torch.Size([25, 20, 28, 28]) from checkpoint, the shape in current model is torch.Size([1, 20, 28, 28]).\n\tsize mismatch for se2.fixed_weights: copying a param with shape torch.Size([25, 40, 12, 12]) from checkpoint, the shape in current model is torch.Size([1, 40, 12, 12])."
     ]
    }
   ],
   "source": [
    "from tools import utils, config, trainer, parts\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn import functional as F\n",
    "from tools import utils\n",
    "import torch.nn as nn\n",
    "\n",
    "plt.style.use('fast')\n",
    "PLOT_DIR = 'plots'\n",
    "\n",
    "cfg = config.from_yaml(\"experiments\\exp9_net6\\config.yaml\")\n",
    "dataset = utils.load_dataset_module(**cfg.data_supervised)\n",
    "dataset.torch_seed()\n",
    "test_loader = dataset.get_test_loader(**cfg.data_supervised)\n",
    "test_dataset = dataset.get_test_dataset()\n",
    "\n",
    "# Trained model\n",
    "model_trained = utils.load_model(**cfg.model)\n",
    "\n",
    "part_manager_trained = parts.PartManager(model_trained)\n",
    "part_manager_trained.enable_all()\n",
    "\n",
    "i_part = 1\n",
    "trn_trained = trainer.ModelTrainer(model_trained, cfg.trainer_sup, part_manager_trained)\n",
    "model_trained.load_state_dict(torch.load(\"experiments\\exp9_net6\\checkpoint.pth\"))\n",
    "model_trained.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoattack import AutoAttack\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_acc_autoattack(model, device, loader):\n",
    "    correct = 0\n",
    "    n_examples = 0\n",
    "\n",
    "    adversary = AutoAttack(model_trained, norm='Linf', eps=8/255, version='custom', attacks_to_run=['apgd-ce', 'apgd-dlr'])\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "    for x, y in tqdm(loader):\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        n_examples += x.shape[0]\n",
    "        \n",
    "    x_all = torch.concat(x_all, dim=0).to(device)\n",
    "    y_all = torch.concat(y_all, dim=0).to(device)\n",
    "    \n",
    "    SAMPLE_SIZE = 1000\n",
    "    sample_idx = np.random.choice(len(x_all), SAMPLE_SIZE, replace=False)\n",
    "    x_all = x_all[sample_idx]\n",
    "    y_all = y_all[sample_idx]\n",
    "        \n",
    "    x_all_attack, y_all_attack = adversary.run_standard_evaluation(x_all, y_all, bs=250, return_labels=True)\n",
    "    return x_all_attack, y_all, y_all_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "class_size = 50\n",
    "classes_to_accumulate = list(range(N_CLASSES))\n",
    "examples = {i: [] for i in range(N_CLASSES)}\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    x, y = test_dataset[i]\n",
    "    if not y in classes_to_accumulate:\n",
    "        i+=1\n",
    "        continue\n",
    "    \n",
    "    examples[y].append(i)\n",
    "    if len(examples[y]) == class_size:\n",
    "        classes_to_accumulate.remove(y)\n",
    "        if len(classes_to_accumulate) == 0:\n",
    "            break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_layer = model_trained.se1\n",
    "\n",
    "part_output_trained_list = [[] for _ in range(N_CLASSES)]\n",
    "y_preds = []\n",
    "y_s = []\n",
    "\n",
    "for class_i, class_examples in examples.items():\n",
    "    for example_i in class_examples:\n",
    "        x, y = test_dataset[example_i]\n",
    "        x = x.unsqueeze(0).to(trn_trained.device)\n",
    "        \n",
    "        y_pred = model_trained(x)\n",
    "        y_pred = np.argmax(y_pred.cpu().detach().numpy())\n",
    "        y_s.append(y)\n",
    "        y_preds.append(y_pred)\n",
    "        \n",
    "        part_output_trained = extract_layer.sigmoid_output\n",
    "        part_output_trained = torch.squeeze(part_output_trained).cpu().detach().numpy()\n",
    "        part_output_trained_list[class_i].append(part_output_trained)\n",
    "\n",
    "print(f\"acc: {(np.array(y_preds) == np.array(y_s)).mean()}\")\n",
    "activations_trained = np.array(part_output_trained_list)\n",
    "activations_trained.shape # i_class, i_example, i_kernel, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = activations_trained\n",
    "for class_i in range(N_CLASSES):\n",
    "    plt.figure(figsize=(25, 4))\n",
    "    plt.imshow(x_plot[class_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att, y_att, y_false = get_acc_autoattack(model_trained, trn_trained.device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "class_size = 50\n",
    "classes_to_accumulate = list(range(N_CLASSES))\n",
    "examples = {i: [] for i in range(N_CLASSES)}\n",
    "\n",
    "for i in range(len(x_att)):\n",
    "    x, y = x_att[i], y_att[i].cpu().detach().numpy().item()\n",
    "    if not y in classes_to_accumulate:\n",
    "        continue\n",
    "    \n",
    "    examples[y].append(i)\n",
    "    if len(examples[y]) == class_size:\n",
    "        classes_to_accumulate.remove(y)\n",
    "        if len(classes_to_accumulate) == 0:\n",
    "            break\n",
    "\n",
    "extract_layer = model_trained.se1\n",
    "\n",
    "part_output_trained_list = [[] for _ in range(N_CLASSES)]\n",
    "y_preds = []\n",
    "y_s = []\n",
    "\n",
    "for class_i, class_examples in examples.items():\n",
    "    for example_i in class_examples:\n",
    "        x, y = x_att[i], y_att[i].cpu().detach().numpy().item()\n",
    "        x = x.unsqueeze(0).to(trn_trained.device)\n",
    "        \n",
    "        y_pred = model_trained(x)\n",
    "        y_pred = np.argmax(y_pred.cpu().detach().numpy())\n",
    "        y_s.append(y)\n",
    "        y_preds.append(y_pred)\n",
    "        \n",
    "        part_output_trained = extract_layer.sigmoid_output\n",
    "        part_output_trained = torch.squeeze(part_output_trained).cpu().detach().numpy()\n",
    "        part_output_trained_list[class_i].append(part_output_trained)\n",
    "\n",
    "print(f\"acc: {(np.array(y_preds) == np.array(y_s)).mean()}\")\n",
    "activations_trained = np.array(part_output_trained_list)\n",
    "activations_trained.shape # i_class, i_example, i_kernel, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = activations_trained\n",
    "for class_i in range(N_CLASSES):\n",
    "    plt.figure(figsize=(25, 5))\n",
    "    plt.imshow(x_plot[class_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d13dd16ed1d9d0f9b50066a4c58f58f02ea0db6cf3822c9f71a8c066ab69665"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
